# NLP Course
Third course in the Natural Language Processing Specialization by deeplearning.ai

## Week 1: Neural Networks for Sentiment Analysis

Learned about neural networks for deep learning, then build a sophisticated tweet classifier that places tweets into positive or negative sentiment categories, using a deep neural network.

### Key Concepts

Feature extraction, Supervised machine learning, Binary classification, Text preprocessing, ReLU, Python classes, Trax, Neural networks

## Week 2: Recurrent Neural Networks for Language Modeling

Learned about the limitations of traditional language models and see how RNNs and GRUs use sequential data for text prediction. Then built my own next-word generator using a simple RNN on Shakespeare text data!

### Key Concepts

N-grams, Gated recurrent units, Recurrent neural networks

## Week 3: LSTMs and Named Entity Recognition

Learned about how long short-term memory units (LSTMs) solve the vanishing gradient problem, and how Named Entity Recognition systems quickly extract important information from text. Then built my own Named Entity Recognition system using an LSTM and data from Kaggle!

### Key Concepts

Vanishing gradients, Named entity recognition, LSTMs, Feature extraction, Part-of-speech tagging, Data generators

## Week 4: Siamese Networks

Learned about Siamese networks, a special type of neural network made of two identical networks that are eventually merged together, then built my own Siamese network that identifies question duplicates in a dataset from Quora.

### Key Concepts

One shot learning
, Triplet loss
, Cosine similarity
, Siamese networks
, Data generators
